name: Model Training and Evaluation

on:
  workflow_dispatch:
    inputs:
      test_size:
        description: 'Test size (fraction between 0 and 1)'
        required: true
        default: '0.2'
      max_iter:
        description: 'Maximum number of iterations for the Logistic Regression model'
        required: true
        default: '10'
      kaggle_key:
        description: 'Kaggle API key'
        required: true
        default: ''

jobs:
  checkout-and-download:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Mask kaggle_key
        run: |
          echo "::add-mask::${{ github.event.inputs.kaggle_key }}"

      - name: Install Kaggle CLI
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-pip
          pip3 install kaggle

      - name: Set up Kaggle API credentials
        run: |
          mkdir -p ~/.kaggle
          echo '{"username":"${{ secrets.KAGGLE_USERNAME }}","key":"${{ github.event.inputs.kaggle_key }}"}' > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      - name: Download dataset from Kaggle
        run: |
          kaggle datasets download -d joebeachcapital/30000-spotify-songs
          unzip 30000-spotify-songs.zip
          kaggle datasets download -d gulczas/spotify-dataset
          unzip spotify-dataset.zip

      - name: Upload dataset artifacts
        uses: actions/upload-artifact@v2
        with:
          name: datasets
          path: |
            spotify_songs.csv
            Spotify_Dataset.csv
          
  train-model:
    runs-on: ubuntu-latest
    needs: checkout-and-download
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy scikit-learn
      
      - name: Download dataset artifacts
        uses: actions/download-artifact@v2
        with:
          name: datasets
          path: .
          
      - name: Train model
        run: |
          python model_creator.py ${{ github.event.inputs.test_size }} ${{ github.event.inputs.max_iter }}

      - name: Upload dataset artifacts
        uses: actions/upload-artifact@v2
        with:
          name: eval_dataset
          path: |
            docker_test_dataset.csv
  eval-model:
    runs-on: ubuntu-latest
    needs: train-model
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy scikit-learn
      
      - name: Download dataset artifacts
        uses: actions/download-artifact@v2
        with:
          name: eval_dataset
          path: .
          
      - name: Evaluate model
        run: |
          python use_model.py

      - name: Upload dataset artifacts
        uses: actions/upload-artifact@v2
        with:
          name: model_metrics
          path: |
            metrics_df.csv
